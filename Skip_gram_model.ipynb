{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/sagarguttal/.cache/kagglehub/datasets/zainabhaddad/reviews-cell-phones-and-accessories-5/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"zainabhaddad/reviews-cell-phones-and-accessories-5\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A30TL5EWN6DFXT</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>christina</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "      <td>Looks Good</td>\n",
       "      <td>1400630400</td>\n",
       "      <td>05 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASY55RVNIL0UD</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>emily l.</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Really great product.</td>\n",
       "      <td>1389657600</td>\n",
       "      <td>01 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2TMXE2AFO7ONB</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>Erica</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE LOVE LOVE</td>\n",
       "      <td>1403740800</td>\n",
       "      <td>06 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWJ0WZQYMYFQ4</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>JM</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1382313600</td>\n",
       "      <td>10 21, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATX7CZYFXI1KW</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>patrice m rogoza</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "      <td>leopard home button sticker for iphone 4s</td>\n",
       "      <td>1359849600</td>\n",
       "      <td>02 3, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin      reviewerName helpful  \\\n",
       "0  A30TL5EWN6DFXT  120401325X         christina  [0, 0]   \n",
       "1   ASY55RVNIL0UD  120401325X          emily l.  [0, 0]   \n",
       "2  A2TMXE2AFO7ONB  120401325X             Erica  [0, 0]   \n",
       "3   AWJ0WZQYMYFQ4  120401325X                JM  [4, 4]   \n",
       "4   ATX7CZYFXI1KW  120401325X  patrice m rogoza  [2, 3]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  They look good and stick good! I just don't li...        4   \n",
       "1  These stickers work like the review says they ...        5   \n",
       "2  These are awesome and make my phone look so st...        5   \n",
       "3  Item arrived in great time and was in perfect ...        4   \n",
       "4  awesome! stays on, and looks great. can be use...        5   \n",
       "\n",
       "                                     summary  unixReviewTime   reviewTime  \n",
       "0                                 Looks Good      1400630400  05 21, 2014  \n",
       "1                      Really great product.      1389657600  01 14, 2014  \n",
       "2                             LOVE LOVE LOVE      1403740800  06 26, 2014  \n",
       "3                                      Cute!      1382313600  10 21, 2013  \n",
       "4  leopard home button sticker for iphone 4s      1359849600   02 3, 2013  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(r\"/Users/sagarguttal/Work/Natural-Language-Processing/Datasets/Cell_Phones_and_Accessories_5.json\", lines=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194439, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a product like this again\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviewText'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they',\n",
       " 'look',\n",
       " 'good',\n",
       " 'and',\n",
       " 'stick',\n",
       " 'good',\n",
       " 'just',\n",
       " 'don',\n",
       " 'like',\n",
       " 'the',\n",
       " 'rounded',\n",
       " 'shape',\n",
       " 'because',\n",
       " 'was',\n",
       " 'always',\n",
       " 'bumping',\n",
       " 'it',\n",
       " 'and',\n",
       " 'siri',\n",
       " 'kept',\n",
       " 'popping',\n",
       " 'up',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'irritating',\n",
       " 'just',\n",
       " 'won',\n",
       " 'buy',\n",
       " 'product',\n",
       " 'like',\n",
       " 'this',\n",
       " 'again']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.utils.simple_preprocess(df['reviewText'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [they, look, good, and, stick, good, just, don...\n",
       "1    [these, stickers, work, like, the, review, say...\n",
       "2    [these, are, awesome, and, make, my, phone, lo...\n",
       "3    [item, arrived, in, great, time, and, was, in,...\n",
       "4    [awesome, stays, on, and, looks, great, can, b...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text = df['reviewText'].apply(gensim.utils.simple_preprocess)\n",
    "review_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x3143d02f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(window=10, vector_size=100, min_count=2, epochs=7,sg=1) # sg parameter is skipgram = 1 means skipgram model architectire True\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 10, 194439)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs, model.window, model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86107121, 117416565)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_word2vec_model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FInd the similar word and similarity between the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.7115426063537598),\n",
       " ('horrible', 0.6776736378669739),\n",
       " ('ok', 0.6636120676994324)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"bad\", topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6581166"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"cheap\",w2=\"inexpensive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35561, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = model.wv.vectors ## extract the word embeddings matrix\n",
    "matrix.shape ## unique words, num feature extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forword pass example how model input one hot codeed vectors passed to model and predict the nearest words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35561, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_out = model.syn1neg\n",
    "W_out.shape ## Output weights from model after applying the softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacabulary list upto 10 words ['the', 'it', 'and', 'to', 'is', 'this', 'of', 'for', 'my', 'that']\n",
      "total Len of vacabulary list 35561\n"
     ]
    }
   ],
   "source": [
    "vocab_lists = model.wv.index_to_key\n",
    "print(\"vacabulary list upto 10 words\", vocab_lists[:10])\n",
    "print(\"total Len of vacabulary list\", len(vocab_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5931,\n",
       " array([-0.00712258,  0.2359466 , -0.03114446, -0.22443694,  0.25148937,\n",
       "        -0.20807847, -0.26968727,  0.22847642, -0.05672771, -0.02954084,\n",
       "         0.23332837, -0.09763193,  0.4943103 ,  0.16879876,  0.06176304,\n",
       "         0.2478795 , -0.56947017,  0.25061676, -0.08822034, -0.18338726,\n",
       "         0.12661164,  0.34964955,  0.17069395, -0.19793949, -0.30371   ,\n",
       "         0.49247393,  0.22642732, -0.21975815,  0.18219912,  0.15755494,\n",
       "         0.13632259,  0.38600272,  0.03332593,  0.03172928, -0.11848735,\n",
       "         0.26687402, -0.19381797,  0.05069618, -0.07853325,  0.14375773,\n",
       "         0.17922062,  0.39787996, -0.39109248,  0.388078  , -0.47051585,\n",
       "         0.10893855,  0.4414546 , -0.43341818, -0.1433949 ,  0.7340807 ,\n",
       "         0.5267529 ,  0.6316635 , -0.27696586,  0.347123  , -0.19481823,\n",
       "        -0.27216196,  0.21183   ,  0.28836504, -0.57246274,  0.53933406,\n",
       "         0.10666623, -0.08862111, -0.10123557,  0.2271278 , -0.11939315,\n",
       "         0.21780343, -0.17280369, -0.44133082,  0.13656293, -0.06655013,\n",
       "        -0.06185734, -0.17868948, -0.34251267,  0.33874422,  0.07162356,\n",
       "         0.72135276, -0.54670477, -0.31081975,  0.05143511, -0.66361195,\n",
       "        -0.5967413 ,  0.48928156,  0.36650223,  0.70375943,  0.12469336,\n",
       "        -0.15803091, -0.252838  ,  0.7045585 ,  0.25947994, -0.26087138,\n",
       "        -0.14680836, -0.17833608,  0.4056574 , -0.00607599, -0.35985523,\n",
       "        -0.30807677, -0.43607414,  0.11604241,  0.11336789,  0.15155308],\n",
       "       dtype=float32),\n",
       " 75)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"sea\"\n",
    "idx = model.wv.key_to_index[word]\n",
    "vec = model.wv.vectors[idx]\n",
    "count = model.wv.get_vecattr(word, \"count\")\n",
    "idx, vec, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 35561)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "one_hot = np.zeros(shape=(1, len(vocab_lists)))\n",
    "one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"sea\"\n",
    "one_hot[0, model.wv.key_to_index[word]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot[0, model.wv.key_to_index[word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35561, 100), (35561, 100), (100, 35561))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape, W_out.shape, W_out.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_proj = np.dot(one_hot, matrix) ## EMbedding of the word sea\n",
    "a_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00712258,  0.2359466 , -0.03114446, -0.22443694,  0.25148937,\n",
       "        -0.20807847, -0.26968727,  0.22847642, -0.05672771, -0.02954084,\n",
       "         0.23332837, -0.09763193,  0.49431029,  0.16879876,  0.06176304,\n",
       "         0.24787951, -0.56947017,  0.25061676, -0.08822034, -0.18338726,\n",
       "         0.12661164,  0.34964955,  0.17069395, -0.19793949, -0.30371001,\n",
       "         0.49247393,  0.22642732, -0.21975815,  0.18219912,  0.15755494,\n",
       "         0.13632259,  0.38600272,  0.03332593,  0.03172928, -0.11848735,\n",
       "         0.26687402, -0.19381797,  0.05069618, -0.07853325,  0.14375773,\n",
       "         0.17922062,  0.39787996, -0.39109248,  0.388078  , -0.47051585,\n",
       "         0.10893855,  0.44145459, -0.43341818, -0.1433949 ,  0.73408067,\n",
       "         0.52675289,  0.6316635 , -0.27696586,  0.347123  , -0.19481823,\n",
       "        -0.27216196,  0.21183001,  0.28836504, -0.57246274,  0.53933406,\n",
       "         0.10666623, -0.08862111, -0.10123557,  0.22712781, -0.11939315,\n",
       "         0.21780343, -0.17280369, -0.44133082,  0.13656293, -0.06655013,\n",
       "        -0.06185734, -0.17868948, -0.34251267,  0.33874422,  0.07162356,\n",
       "         0.72135276, -0.54670477, -0.31081975,  0.05143511, -0.66361195,\n",
       "        -0.59674132,  0.48928156,  0.36650223,  0.70375943,  0.12469336,\n",
       "        -0.15803091, -0.25283799,  0.70455849,  0.25947994, -0.26087138,\n",
       "        -0.14680836, -0.17833608,  0.40565741, -0.00607599, -0.35985523,\n",
       "        -0.30807677, -0.43607414,  0.11604241,  0.11336789,  0.15155308]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_proj "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 35561)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_out = np.dot(a_proj, W_out.T)\n",
    "z_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 35561)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_out = np.exp(z_out)/np.sum(np.exp(z_out))\n",
    "a_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index number 5931 and corrsponding word sea and score 0.06034282671022149\n",
      "index number 7159 and corrsponding word tan and score 0.0015840976364057248\n",
      "index number 8618 and corrsponding word jet and score 0.0010346074505529377\n",
      "index number 7451 and corrsponding word ocean and score 0.0009873535977361304\n",
      "index number 7215 and corrsponding word shops and score 0.0009802432025984933\n",
      "index number 8443 and corrsponding word garden and score 0.0009225551221556965\n",
      "index number 3381 and corrsponding word el and score 0.0008612473022258687\n",
      "index number 10610 and corrsponding word blues and score 0.0008481035638122385\n",
      "index number 3769 and corrsponding word la and score 0.0008480412453309058\n",
      "index number 4713 and corrsponding word eacute and score 0.0008022477086344492\n"
     ]
    }
   ],
   "source": [
    "a_out = a_out.flatten()\n",
    "indices = np.argsort(a_out) ## Sort in accedensing order\n",
    "indices = indices[::-1] ## Sort in descending order\n",
    "\n",
    "for i in range(10): ## TOp 10 nearest words word sea\n",
    "    print(f\"index number {indices[i]} and corrsponding word {model.wv.index_to_key[indices[i]]} and score {a_out[indices[i]]}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
